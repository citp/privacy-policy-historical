> *The following text is extracted and transformed from the schneier.com privacy policy that was archived on 2018-04-16. Please check the [original snapshot on the Wayback Machine](https://web.archive.org/web/20180416112349id_/https%3A//www.schneier.com/cgi-bin/mt/mt-search.cgi%3Fsearch%3Dprivacy%26__mode%3Dtag%26IncludeBlogs%3D2%26limit%3D10%26page%3D1) for the most accurate reproduction.*

# Schneier on Security: Blog Entries Tagged privacy

Page 1 of 115

### [COPPA Compliance](https://www.schneier.com/blog/archives/2018/04/coppa_complianc.html)

Interesting research: "['Won't Somebody Think of the Children?' Examining COPPA Compliance at Scale](https://petsymposium.org/2018/files/papers/issue3/popets-2018-0021.pdf)":

> **Abstract:** We present a scalable dynamic analysis framework that allows for the automatic evaluation of the privacy behaviors of Android apps. We use our system to analyze mobile apps' compliance with the Children's Online Privacy Protection Act (COPPA), one of the few stringent privacy laws in the U.S. Based on our automated analysis of 5,855 of the most popular free children's apps, we found that a majority are potentially in violation of COPPA, mainly due to their use of third-party SDKs. While many of these SDKs offer configuration options to respect COPPA by disabling tracking and behavioral advertising, our data suggest that a majority of apps either do not make use of these options or incorrectly propagate them across mediation SDKs. Worse, we observed that 19% of children's apps collect identifiers or other personally identifiable information (PII) via SDKs whose terms of service outright prohibit their use in child-directed apps. Finally, we show that efforts by Google to limit tracking through the use of a resettable advertising ID have had little success: of the 3,454 apps that share the resettable ID with advertisers, 66% transmit other, non-resettable, persistent identifiers as well, negating any intended privacy-preserving properties of the advertising ID.

[Posted on April 13, 2018 at 6:43 AM](https://www.schneier.com/blog/archives/2018/04/coppa_complianc.html) • [View Comments](https://www.schneier.com/blog/archives/2018/04/coppa_complianc.html#comments)

### [Facebook and Cambridge Analytica](https://www.schneier.com/blog/archives/2018/03/facebook_and_ca.html)

In the wake of the Cambridge Analytica scandal, news articles and commentators have focused on what Facebook knows about us. A lot, it turns out. It collects data from our posts, our likes, our [photos](https://www.express.co.uk/life-style/science-technology/751009/Facebook-Scan-Photos-Data-Collection), things we [type and delete](http://www.businessinsider.com/facebook-saves-stuff-you-start-typing-and-the-delete-2013-12) without posting, and things we do while [not on Facebook](https://www.theguardian.com/technology/2017/jul/03/facebook-track-browsing-history-california-lawsuit) and even when we're offline. It [buys data](https://www.propublica.org/article/facebook-doesnt-tell-users-everything-it-really-knows-about-them) about us from others. And it can infer even more: our sexual orientation, political beliefs, relationship status, drug use, and other [personality traits](http://www.pnas.org/content/early/2013/03/06/1218772110) \-- even if we didn't take the [personality test](http://www.businessinsider.com/facebook-personality-test-cambridge-analytica-data-trump-election-2018-3) that Cambridge Analytica developed.

But for every article about Facebook's creepy stalker behavior, thousands of other companies are breathing a collective sigh of relief that it's Facebook and not them in the spotlight. Because while Facebook is one of the biggest players in this space, there are thousands of other companies that spy on and manipulate us for profit.

Harvard Business School professor Shoshana Zuboff calls it "[surveillance capitalism](https://www.amazon.com/Age-Surveillance-Capitalism-Future-Frontier/dp/1610395697/ref=sr_1_sc_1)." And as creepy as Facebook is turning out to be, the entire industry is far creepier. It has existed in secret far too long, and it's up to lawmakers to force these companies into the public spotlight, where we can all decide if this is how we want society to operate and -- if not -- what to do about it.

There are [2,500 to 4,000](http://www.newsweek.com/secretive-world-selling-data-about-you-464789) data brokers in the United States whose business is buying and selling our personal data. Last year, Equifax was in [the](https://www.nytimes.com/2017/09/07/business/equifax-cyberattack.html) [news](https://www.nytimes.com/2017/10/02/business/equifax-breach.html) when hackers stole personal information on 150 million people, including Social Security numbers, birth dates, addresses, and driver's license numbers.

You certainly didn't give it permission to collect any of that information. Equifax is one of those thousands of data brokers, most of them you've never heard of, [selling](https://www.forbes.com/sites/forrester/2017/09/08/equifax-does-more-than-credit-scores/#324765b219d8) your personal information without your knowledge or consent to pretty much anyone who will pay for it.

Surveillance capitalism takes this one step further. Companies like Facebook and Google offer you free services in exchange for your data. Google's surveillance isn't in the news, but it's startlingly intimate. We never lie to our search engines. Our interests and curiosities, hopes and fears, desires and sexual proclivities, are all collected and saved. Add to that the websites we visit that Google tracks through its advertising network, our Gmail accounts, our movements via [Google Maps](https://mashable.com/2015/07/22/google-maps-your-timeline/#_XGlE24.YGqq), and what it can collect from our smartphones.

That phone is probably the most intimate surveillance device ever invented. It tracks our location continuously, so it knows where we live, where we work, and where we spend our time. It's the first and last thing we check in a day, so it knows when we wake up and when we go to sleep. We all have one, so it knows who we sleep with. Uber used just [some of that information](https://gigaom.com/2012/03/26/uber-one-night-stands/) to detect one-night stands; your smartphone provider and any app you allow to collect location data knows a lot more.

Surveillance capitalism drives much of the internet. It's behind most of the "free" services, and many of the paid ones as well. Its goal is psychological manipulation, in the form of personalized advertising to persuade you to buy something or do something, like vote for a candidate. And while the individualized profile-driven manipulation exposed by Cambridge Analytica feels abhorrent, it's really no different from what every company wants in the end. This is why all your personal information is collected, and this is why it is so valuable. Companies that can understand it can use it against you.

None of this is new. The media has been reporting on surveillance capitalism for years. In 2015, I wrote a [book](https://www.schneier.com/books/data_and_goliath/) about it. Back in 2010, the Wall Street Journal [published](http://juliaangwin.com/the-what-they-know-series/) [an](https://ashkansoltani.org/work/what-they-know/) award-winning two-year series about how people are tracked both online and offline, titled "What They Know."

Surveillance capitalism is deeply embedded in our increasingly computerized society, and if the extent of it came to light there would be broad demands for limits and regulation. But because this industry can largely operate in secret, only occasionally exposed after a data breach or investigative report, we remain mostly ignorant of its reach.

This might change soon. In 2016, the European Union passed the comprehensive General Data Protection Regulation, or GDPR. The details of the law are far too complex to explain here, but some of the things it [mandates](https://www.cennydd.com/writing/a-techies-rough-guide-to-gdpr) are that personal data of EU citizens can only be collected and saved for "specific, explicit, and legitimate purposes," and only with explicit consent of the user. Consent can't be buried in the terms and conditions, nor can it be assumed unless the user opts in. This law will take effect in May, and companies worldwide are bracing for its enforcement.

Because pretty much all surveillance capitalism companies collect data on Europeans, this will expose the industry like nothing else. Here's just one example. In preparation for this law, PayPal [quietly](https://www.paypal.com/ie/webapps/mpp/ua/third-parties-list) [published](https://rebecca-ricks.com/paypal-data/) a list of over 600 companies it might share your personal data with. What will it be like when every company has to publish this sort of information, and explicitly explain how it's using your personal data? We're about to find out.

In the wake of this scandal, even Mark Zuckerberg [said](https://www.wired.com/story/mark-zuckerberg-talks-to-wired-about-facebooks-privacy-problem/) [that](https://www.theverge.com/2018/3/21/17150270/mark-zuckerberg-facebook-regulated) his industry probably should be regulated, although he's certainly not wishing for the sorts of comprehensive regulation the GDPR is bringing to Europe.

He's right. Surveillance capitalism has operated without constraints for far too long. And advances in both big data analysis and artificial intelligence will make tomorrow's applications far creepier than today's. Regulation is the [only answer](https://www.nytimes.com/2018/03/24/opinion/sunday/delete-facebook-does-not-fix-problem.html).

The first step to any regulation is transparency. Who has our data? Is it accurate? What are they doing with it? Who are they selling it to? How are they securing it? Can we delete it? I don't see any hope of Congress passing a GDPR-like data protection law anytime soon, but it's not too far-fetched to demand laws requiring these companies to be more transparent in what they're doing.

One of the responses to the Cambridge Analytica scandal is that people are deleting their Facebook accounts. It's [hard](https://pageflows.com/blog/delete-facebook/) to do right, and doesn't do anything about the data that Facebook [collects](https://www.theverge.com/2016/5/27/11795248/facebook-ad-network-non-users-cookies-plug-ins) [about](https://mashable.com/2013/06/26/facebook-shadow-profiles/#NtiWOxH36Zq9) [people](https://gizmodo.com/how-facebook-figures-out-everyone-youve-ever-met-1819822691?IR=T) who don't use Facebook. But it's a start. The market can put pressure on these companies to reduce their spying on us, but it can only do that if we force the industry out of its secret shadows.

This essay [previously appeared](https://www.cnn.com/2018/03/26/opinions/data-company-spying-opinion-schneier/index.html) on CNN.com.

EDITED TO ADD (4/2): Slashdot [thread](https://yro.slashdot.org/story/18/03/31/0253219/thousands-of-companies-are-spying-on-you).

[Posted on March 29, 2018 at 3:50 PM](https://www.schneier.com/blog/archives/2018/03/facebook_and_ca.html) • [View Comments](https://www.schneier.com/blog/archives/2018/03/facebook_and_ca.html#comments)

### [Zeynep Tufekci on Facebook and Cambridge Analytica](https://www.schneier.com/blog/archives/2018/03/zeynep_tufekci_.html)

Zeynep Tufekci is [particularly cogent](https://www.nytimes.com/2018/03/19/opinion/facebook-cambridge-analytica.html) about Facebook and Cambridge Analytica.

Several news outlets asked me to write about this issue. I didn't, because 1) my [book manuscript](https://www.schneier.com/blog/archives/2018/01/new_book_coming.html) is due on Monday (finally!), and 2) I knew Zeynep would say what I would say, only better.

[Posted on March 23, 2018 at 2:21 PM](https://www.schneier.com/blog/archives/2018/03/zeynep_tufekci_.html) • [View Comments](https://www.schneier.com/blog/archives/2018/03/zeynep_tufekci_.html#comments)

### [The 600+ Companies PayPal Shares Your Data With](https://www.schneier.com/blog/archives/2018/03/the_600_compani.html)

One of the effects of GDPR -- the new EU General Data Protection Regulation -- is that we're all going to be learning a lot more about who collects our data and what they do with it. Consider PayPal, that [just released](https://www.paypal.com/ie/webapps/mpp/ua/third-parties-list) a list of over 600 companies they share customer data with. [Here's](https://rebecca-ricks.com/paypal-data/) a good visualization of that data.

Is 600 companies unusual? Is it more than average? Less? We'll soon know. 

[Posted on March 14, 2018 at 6:24 AM](https://www.schneier.com/blog/archives/2018/03/the_600_compani.html) • [View Comments](https://www.schneier.com/blog/archives/2018/03/the_600_compani.html#comments)

### [Apple to Store Encryption Keys in China](https://www.schneier.com/blog/archives/2018/02/apple_to_store_.html)

Apple is bowing to pressure from the Chinese government and [storing encryption keys](https://gizmodo.com/apple-moves-chinese-icloud-encryption-keys-to-china-wo-1823312628) in China. While I would prefer it if it would take a stand against China, I really can't blame it for putting its business model ahead of its desires for customer privacy.

Two [more](https://www.theverge.com/2018/2/26/17052802/apple-icloud-encryption-keys-storage-china) [articles](https://techcrunch.com/2018/02/25/apple-is-moving-icloud-encryption-keys-for-chinese-users-to-china/).

[Posted on February 28, 2018 at 6:19 AM](https://www.schneier.com/blog/archives/2018/02/apple_to_store_.html) • [View Comments](https://www.schneier.com/blog/archives/2018/02/apple_to_store_.html#comments)

### [E-Mail Leaves an Evidence Trail](https://www.schneier.com/blog/archives/2018/02/e-mail_leaves_a.html)

If you're going to commit an illegal act, it's best [not to discuss it in e-mail](https://slate.com/technology/2018/02/paul-manafort-couldnt-convert-pdfs-to-word-documents.html). It's also best to Google tech instructions rather than asking someone else to do it:

> One new detail from the indictment, however, points to just _how_ unsophisticated Manafort seems to have been. Here's the relevant passage from the indictment. I've bolded the most important bits: 
>
>> Manafort and Gates made numerous false and fraudulent representations to secure the loans. For example, Manafort provided the bank with doctored [profit and loss statements] for [Davis Manafort Inc.] for both 2015 and 2016, overstating its income by millions of dollars. The doctored 2015 DMI P&L submitted to Lender D was the same false statement previously submitted to Lender C, which overstated DMI's income by more than $4 million. The doctored 2016 DMI P&L was inflated by Manafort by more than $3.5 million. To create the false 2016 P&L, on or about October 21, 2016, **Manafort emailed Gates a .pdf version** of the real 2016 DMI P&L, which showed a loss of more than $600,000. **Gates converted that .pdf into a "Word" document so that it could be edited** , which Gates sent back to Manafort. **Manafort altered that "Word" document** by adding more than $3.5 million in income. He then **sent this falsified P &L to Gates and asked that the "Word" document be converted back to a .pdf, which Gates did and returned to Manafort**. Manafort then sent the falsified 2016 DMI P&L .pdf to Lender D.
> 
> So here's the essence of what went wrong for Manafort and Gates, according to Mueller's investigation: Manafort allegedly wanted to falsify his company's income, but he couldn't figure out how to edit the PDF. He therefore had Gates turn it into a Microsoft Word document for him, which led the two to bounce the documents back-and-forth over email. As attorney and blogger Susan Simpson [notes on Twitter](https://twitter.com/TheViewFromLL2/status/966807752696909826), Manafort's inability to complete a basic task on his own seems to have effectively "created an incriminating paper trail."

If there's a lesson here, it's that the Internet constantly generates data about what people are doing on it, and that data is all potential evidence. The FBI is 100% wrong that they're [going dark](https://www.documentcloud.org/documents/4325815-Director-Wray-Testimony.html#document/p5/a392750); it's really the [golden age of surveillance](https://www.judiciary.senate.gov/imo/media/doc/07-08-15%20Swire%20Testimony.pdf), and the [FBI's panic](https://cyber.harvard.edu/pubrelease/dont-panic/) is really just its own [lack of technical sophistication](https://www.wired.com/2013/01/wiretap-backdoors/). 

[Posted on February 26, 2018 at 3:39 PM](https://www.schneier.com/blog/archives/2018/02/e-mail_leaves_a.html) • [View Comments](https://www.schneier.com/blog/archives/2018/02/e-mail_leaves_a.html#comments)

### [Living in a Smart Home](https://www.schneier.com/blog/archives/2018/02/living_in_a_sma.html)

In "[The House that Spied on Me](https://gizmodo.com/the-house-that-spied-on-me-1822429852)," Kashmir Hill outfits her home to be as "smart" as possible and writes about the results.

[Posted on February 9, 2018 at 7:59 AM](https://www.schneier.com/blog/archives/2018/02/living_in_a_sma.html) • [View Comments](https://www.schneier.com/blog/archives/2018/02/living_in_a_sma.html#comments)

### [After Section 702 Reauthorization](https://www.schneier.com/blog/archives/2018/01/after_section_7.html)

For over a decade, civil libertarians have been fighting government mass surveillance of innocent Americans over the Internet. We've just lost an important battle. On January 18, [President Trump](https://www.politico.com/story/2018/01/19/trump-surveillance-extension-351136) [signed](https://www.wired.com/story/fisa-section-702-renewal-congress/) the renewal of Section 702, domestic mass surveillance became effectively a permanent part of US law.

Section 702 was initially passed in 2008, as an amendment to the Foreign Intelligence Surveillance Act of 1978. As the title of that law says, it was billed as a way for the NSA to spy on non-Americans located outside the United States. It was supposed to be an efficiency and cost-saving measure: the NSA was already permitted to tap communications cables located outside the country, and it was already permitted to tap communications cables from one foreign country to another that passed through the United States. Section 702 allowed it to tap those cables from inside the United States, where it was easier. It also allowed the NSA to request surveillance data directly from Internet companies under a program called PRISM.

The problem is that this authority also gave the NSA the ability to collect foreign communications and data in a way that [inherently and intentionally](https://www.eff.org/pages/Incidental-collection) also swept up Americans' communications as well, without a warrant. Other law enforcement agencies are allowed to ask the NSA to search those communications, give their contents to the FBI and other agencies and then [lie about their origins](https://theintercept.com/2017/11/30/nsa-surveillance-fisa-section-702/) in court.

In 1978, after Watergate had revealed the Nixon administration's abuses of power, we erected a wall between intelligence and law enforcement that prevented precisely this kind of sharing of surveillance data under any authority less restrictive than the Fourth Amendment. Weakening that wall is incredibly dangerous, and the NSA should never have been given this authority in the first place.

Arguably, it never was. The NSA had been doing this type of surveillance illegally for years, something that was first [made public](http://www.nytimes.com/2006/04/13/us/nationalspecial3/13nsa.html) in 2006. Section 702 was secretly used as a way to paper over that illegal collection, but nothing in the text of the later amendment gives the NSA this authority. We didn't know that the NSA was using this law as the statutory basis for this surveillance until Edward Snowden [showed us](https://www.theguardian.com/world/2013/aug/09/nsa-loophole-warrantless-searches-email-calls) in 2013.

Civil libertarians have been battling this law in both Congress and the courts ever since it was proposed, and the NSA's domestic surveillance activities even longer. What this most recent vote tells me is that we've lost that fight.

Section 702 was passed under George W. Bush in 2008, reauthorized under Barack Obama in 2012, and now reauthorized again under Trump. In all three cases, congressional support was bipartisan. It has survived multiple lawsuits by the Electronic Frontier Foundation, the ACLU, and others. It has survived the revelations by Snowden that it was being used far more extensively than Congress or the public believed, and numerous [public reports](https://www.newamerica.org/oti/blog/history-fisa-section-702-compliance-violations/) of violations of the law. It has even survived [Trump's belief](http://www.washingtonexaminer.com/trump-signs-fisa-reauthorization-says-different-from-law-that-was-so-wrongly-abused-during-the-election/article/2646505) that he was being personally spied on by the intelligence community, as well as any congressional fears that Trump could abuse the authority in the coming years. And though this extension lasts only six years, it's inconceivable to me that it will ever be repealed at this point.

So what do we do? If we can't fight this particular statutory authority, where's the new front on surveillance? There are, it turns out, reasonable modifications that target surveillance more generally, and not in terms of any particular statutory authority. We need to look at US surveillance law more generally.

First, we need to strengthen the minimization procedures to limit incidental collection. Since the Internet was developed, all the world's communications travel around in a single global network. It's impossible to collect only foreign communications, because they're invariably mixed in with domestic communications. This is called "incidental" collection, but that's a misleading name. It's collected knowingly, and searched regularly. The intelligence community needs much stronger restrictions on which American communications channels it can access without a court order, and rules that require they delete the data if they inadvertently collect it. More importantly, "collection" is defined as the point the NSA takes a copy of the communications, and not later when they search their databases.

Second, we need to limit how other law enforcement agencies can use incidentally collected information. Today, those agencies can query a database of incidental collection on Americans. The NSA can legally pass information to those other agencies. This has to stop. Data collected by the NSA under its foreign surveillance authority should not be used as a vehicle for domestic surveillance.

The most recent reauthorization modified this lightly, forcing the FBI to obtain a court order when querying the 702 data for a criminal investigation. There are still exceptions and loopholes, though.

Third, we need to end what's called "parallel construction." Today, when a law enforcement agency uses evidence found in this NSA database to arrest someone, it doesn't have to disclose that fact in court. It can reconstruct the evidence in some other manner once it knows about it, and then pretend it learned of it that way. This right to lie to the judge and the defense is corrosive to liberty, and it must end.

Pressure to reform the NSA will probably first come from Europe. Already, European Union courts have pointed to warrantless NSA surveillance as a reason to keep Europeans' data out of US hands. Right now, there is a fragile agreement between the EU and the United States ­-- called "[Privacy Shield](https://www.privacyshield.gov/)" -- ­that requires Americans to maintain certain safeguards for international data flows. NSA surveillance goes against that, and it's only a matter of time before EU courts start ruling this way. That'll have significant effects on both government and corporate surveillance of Europeans and, by extension, the entire world.

Further pressure will come from the increased surveillance coming from the Internet of Things. When your home, car, and body are awash in sensors, privacy from both governments and corporations will become increasingly important. Sooner or later, society will reach a tipping point where it's all too much. When that happens, we're going to see significant pushback against surveillance of all kinds. That's when we'll get new laws that revise all government authorities in this area: a clean sweep for a new world, one with new norms and new fears.

It's possible that a federal court will rule on Section 702. Although there have been many lawsuits challenging the legality of what the NSA is doing and the constitutionality of the 702 program, no court has ever ruled on those questions. The Bush and Obama administrations successfully argued that defendants don't have legal standing to sue. That is, they have no right to sue because they don't know they're being targeted. If any of the lawsuits can get past that, things might change dramatically.

Meanwhile, much of this is the responsibility of the tech sector. This problem exists primarily because Internet companies collect and retain so much personal data and allow it to be sent across the network with minimal security. Since the government has abdicated its responsibility to protect our privacy and security, these companies need to step up: Minimize data collection. Don't save data longer than absolutely necessary. Encrypt what has to be saved. Well-designed Internet services will safeguard users, regardless of government surveillance authority.

For the rest of us concerned about this, it's important not to give up hope. Everything we do to keep the issue in the public eye ­-- and not just when the authority comes up for reauthorization again in 2024 -- hastens the day when we will reaffirm our rights to privacy in the digital age.

This essay [previously appeared](https://www.washingtonpost.com/news/posteverything/wp/2018/01/25/how-to-fight-mass-surveillance-even-though-congress-just-reauthorized-it/) in the _Washington Post_.

[Posted on January 31, 2018 at 6:06 AM](https://www.schneier.com/blog/archives/2018/01/after_section_7.html) • [View Comments](https://www.schneier.com/blog/archives/2018/01/after_section_7.html#comments)

### [Detecting Drone Surveillance with Traffic Analysis](https://www.schneier.com/blog/archives/2018/01/detecting_drone.html)

This is [clever](https://www.wired.com/story/a-clever-radio-trick-can-tell-if-a-drone-is-watching-you/):

> Researchers at Ben Gurion University in Beer Sheva, Israel have built a proof-of-concept system for counter-surveillance against spy drones that demonstrates a clever, if not exactly simple, way to determine whether a certain person or object is under aerial surveillance. They first generate a recognizable pattern on whatever subject­ -- a window, say -- someone might want to guard from potential surveillance. Then they remotely intercept a drone's radio signals to look for that pattern in the streaming video the drone sends back to its operator. If they spot it, they can determine that the drone is looking at their subject. 
> 
> In other words, they can see what the drone sees, pulling out their recognizable pattern from the radio signal, even without breaking the drone's encrypted video.

The details have to do with the way drone video is compressed:

> The researchers' technique takes advantage of an efficiency feature streaming video has used for years, known as "delta frames." Instead of encoding video as a series of raw images, it's compressed into a series of changes from the previous image in the video. That means when a streaming video shows a still object, it transmits fewer bytes of data than when it shows one that moves or changes color. 
> 
> That compression feature can reveal key information about the content of the video to someone who's intercepting the streaming data, security researchers have shown in recent research, even when the data is encrypted.

Research [paper](https://arxiv.org/pdf/1801.03074.pdf) and [video](https://www.youtube.com/watch?v=4icQwducz68). 

[Posted on January 24, 2018 at 5:28 AM](https://www.schneier.com/blog/archives/2018/01/detecting_drone.html) • [View Comments](https://www.schneier.com/blog/archives/2018/01/detecting_drone.html#comments)
